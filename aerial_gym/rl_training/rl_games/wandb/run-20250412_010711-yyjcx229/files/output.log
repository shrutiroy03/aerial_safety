Started to train
[isaacgym:gymutil.py] Unknown args:  ['--file=./ppo_aerial_quad_navigation.yaml', '--train', '--track', '--wandb-project-name=safe-rl', '--wandb-entity=shrutiroy03-princeton-university']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
[37m[6135 ms][base_task] - INFO : Setting seed: 10 (base_task.py:38)
[37m[6135 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[6136 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[6136 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[6136 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[6136 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[31m[6136 ms][IsaacGymEnvManager] - CRITICAL : 
[31m Setting graphics device to -1.
[31m This is done because the simulation is run in headless mode and no Isaac Gym cameras are used.
[31m No need to worry. The simulation and warp rendering will work as expected. (IGE_env_manager.py:112)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: -1 (IGE_env_manager.py:119)
[37m[6136 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[6136 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[6137 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[6877 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[6877 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[6929 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[6930 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[6930 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[6930 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[6930 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[6930 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[6930 ms][base_multirotor] - WARNING : Creating 512 multirotors. (base_multirotor.py:32)
[37m[6930 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[6930 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[6930 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6930 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6932 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6933 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6934 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6935 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6936 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6936 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6937 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6938 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6939 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6940 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6965 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[7114 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:427)
[33m[7114 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:430)
[31m[7114 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:433)
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
creating render graph
Module warp.utils load on device 'cuda:0' took 1.30 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 6.40 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 9.41 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 4.67 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
Box(-1.0, 1.0, (4,), float32) Box(-inf, inf, (81,), float32)
seq_length: 4
current training device: cuda:0
build mlp: 81
RunningMeanStd:  (1,)
RunningMeanStd:  (81,)
[37m[8148 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[8184 ms][IsaacGymEnvManager] - WARNING : Headless: True (IGE_env_manager.py:424)
[37m[8184 ms][IsaacGymEnvManager] - INFO : Headless mode. Viewer not created. (IGE_env_manager.py:434)
[33m[8651 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[8843 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[8844 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/vae_image_encoder.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = clean_state_dict(torch.load(weight_file_path))
/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/gym/spaces/box.py:84: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py:254: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(enabled=self.mixed_precision)
[31m[10600 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[10604 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
[31m         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
[31m         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
[31m         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
[31m         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
[31m         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
[31m         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
[31m         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
[31m        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
[31m        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
[31m        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
[31m        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
[31m        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
[31m        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
[31m        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
[31m        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
[31m        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
[31m        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
[31m        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
[31m        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
[31m        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
[31m        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
[31m        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
[31m        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
[31m        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
[31m        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
[31m        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
[31m        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
[31m        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
[31m        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
[31m        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
[31m        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
[31m        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,
[31m        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,
[31m        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,
[31m        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,
[31m        504, 505, 506, 507, 508, 509, 510, 511], device='cuda:0') (navigation_task.py:196)
[31m[10607 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
Traceback (most recent call last):
  File "runner.py", line 328, in <module>
    runner.run(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 133, in run
    self.run_train(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 116, in run_train
    agent.train()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1318, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1182, in train_epoch
    batch_dict = self.play_steps()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 752, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 519, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "runner.py", line 57, in step
    return self.env.step(actions)
  File "runner.py", line 35, in step
    observations, rewards, terminated, truncated, infos = super().step(action)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 345, in step
    self.process_image_observation()
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 278, in process_image_observation
    self.image_latents[:] = self.vae_model.encode(image_obs)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/vae_image_encoder.py", line 49, in encode
    z_sampled, means, *_ = self.vae_model.encode(interpolated_image)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/VAE.py", line 250, in encode
    z = self.encoder(img)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/VAE.py", line 117, in forward
    return self.encode(img)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/VAE.py", line 125, in encode
    x0_0 = self.conv0(img)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 5.70 GiB of which 705.88 MiB is free. Including non-PyTorch memory, this process has 4.98 GiB memory in use. Of the allocated memory 443.79 MiB is allocated by PyTorch, and 8.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "runner.py", line 328, in <module>
    runner.run(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 133, in run
    self.run_train(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 116, in run_train
    agent.train()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1318, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1182, in train_epoch
    batch_dict = self.play_steps()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 752, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 519, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "runner.py", line 57, in step
    return self.env.step(actions)
  File "runner.py", line 35, in step
    observations, rewards, terminated, truncated, infos = super().step(action)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 345, in step
    self.process_image_observation()
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 278, in process_image_observation
    self.image_latents[:] = self.vae_model.encode(image_obs)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/vae_image_encoder.py", line 49, in encode
    z_sampled, means, *_ = self.vae_model.encode(interpolated_image)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/VAE.py", line 250, in encode
    z = self.encoder(img)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/VAE.py", line 117, in forward
    return self.encode(img)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/VAE.py", line 125, in encode
    x0_0 = self.conv0(img)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 5.70 GiB of which 705.88 MiB is free. Including non-PyTorch memory, this process has 4.98 GiB memory in use. Of the allocated memory 443.79 MiB is allocated by PyTorch, and 8.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)