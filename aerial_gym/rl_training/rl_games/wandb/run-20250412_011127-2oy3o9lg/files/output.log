Started to train
[isaacgym:gymutil.py] Unknown args:  ['--file=./ppo_aerial_quad_navigation.yaml', '--train', '--track', '--wandb-project-name=safe-rl', '--wandb-entity=shrutiroy03-princeton-university']
Not connected to PVD
+++ Using GPU PhysX
Physics Engine: PhysX
Physics Device: cuda:0
GPU Pipeline: enabled
*** Can't create empty tensor
WARNING: allocation matrix is not full rank. Rank: 4
[37m[6099 ms][base_task] - INFO : Setting seed: 10 (base_task.py:38)
[37m[6100 ms][navigation_task] - INFO : Building environment for navigation task. (navigation_task.py:44)
[37m[6100 ms][navigation_task] - INFO : Sim Name: base_sim, Env Name: env_with_obstacles, Robot Name: lmf2, Controller Name: lmf2_velocity_control (navigation_task.py:45)
[37m[6100 ms][env_manager] - INFO : Populating environments. (env_manager.py:73)
[37m[6100 ms][env_manager] - INFO : Creating simulation instance. (env_manager.py:87)
[37m[6100 ms][env_manager] - INFO : Instantiating IGE object. (env_manager.py:88)
[37m[6100 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Environment (IGE_env_manager.py:41)
[37m[6100 ms][IsaacGymEnvManager] - INFO : Acquiring gym object (IGE_env_manager.py:73)
[37m[6100 ms][IsaacGymEnvManager] - INFO : Acquired gym object (IGE_env_manager.py:75)
[37m[6101 ms][IsaacGymEnvManager] - INFO : Fixing devices (IGE_env_manager.py:89)
[37m[6101 ms][IsaacGymEnvManager] - INFO : Using GPU pipeline for simulation. (IGE_env_manager.py:102)
[37m[6101 ms][IsaacGymEnvManager] - INFO : Sim Device type: cuda, Sim Device ID: 0 (IGE_env_manager.py:105)
[31m[6101 ms][IsaacGymEnvManager] - CRITICAL : 
[31m Setting graphics device to -1.
[31m This is done because the simulation is run in headless mode and no Isaac Gym cameras are used.
[31m No need to worry. The simulation and warp rendering will work as expected. (IGE_env_manager.py:112)
[37m[6101 ms][IsaacGymEnvManager] - INFO : Graphics Device ID: -1 (IGE_env_manager.py:119)
[37m[6101 ms][IsaacGymEnvManager] - INFO : Creating Isaac Gym Simulation Object (IGE_env_manager.py:120)
[33m[6101 ms][IsaacGymEnvManager] - WARNING : If you have set the CUDA_VISIBLE_DEVICES environment variable, please ensure that you set it
[33mto a particular one that works for your system to use the viewer or Isaac Gym cameras.
[33mIf you want to run parallel simulations on multiple GPUs with camera sensors,
[33mplease disable Isaac Gym and use warp (by setting use_warp=True), set the viewer to headless. (IGE_env_manager.py:127)
[33m[6101 ms][IsaacGymEnvManager] - WARNING : If you see a segfault in the next lines, it is because of the discrepancy between the CUDA device and the graphics device.
[33mPlease ensure that the CUDA device and the graphics device are the same. (IGE_env_manager.py:132)
[37m[6835 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Simulation Object (IGE_env_manager.py:136)
[37m[6835 ms][IsaacGymEnvManager] - INFO : Created Isaac Gym Environment (IGE_env_manager.py:43)
[37m[6889 ms][env_manager] - INFO : IGE object instantiated. (env_manager.py:109)
[37m[6889 ms][env_manager] - INFO : Creating warp environment. (env_manager.py:112)
[37m[6889 ms][env_manager] - INFO : Warp environment created. (env_manager.py:114)
[37m[6889 ms][env_manager] - INFO : Creating robot manager. (env_manager.py:118)
[37m[6889 ms][BaseRobot] - INFO : [DONE] Initializing controller (base_robot.py:26)
[37m[6889 ms][BaseRobot] - INFO : Initializing controller lmf2_velocity_control (base_robot.py:29)
[33m[6889 ms][base_multirotor] - WARNING : Creating 128 multirotors. (base_multirotor.py:32)
[37m[6889 ms][env_manager] - INFO : [DONE] Creating robot manager. (env_manager.py:123)
[37m[6889 ms][env_manager] - INFO : [DONE] Creating simulation instance. (env_manager.py:125)
[37m[6890 ms][asset_loader] - INFO : Loading asset: model.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6890 ms][asset_loader] - INFO : Loading asset: panel.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6892 ms][asset_loader] - INFO : Loading asset: cuboidal_rod.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6893 ms][asset_loader] - INFO : Loading asset: small_cube.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6893 ms][asset_loader] - INFO : Loading asset: 1_x_1_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6894 ms][asset_loader] - INFO : Loading asset: left_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6895 ms][asset_loader] - INFO : Loading asset: right_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6896 ms][asset_loader] - INFO : Loading asset: back_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6897 ms][asset_loader] - INFO : Loading asset: front_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6897 ms][asset_loader] - INFO : Loading asset: bottom_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6898 ms][asset_loader] - INFO : Loading asset: top_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6899 ms][asset_loader] - INFO : Loading asset: 0_5_x_0_5_wall.urdf for the first time. Next use of this asset will be via the asset buffer. (asset_loader.py:71)
[37m[6906 ms][env_manager] - INFO : Populating environment 0 (env_manager.py:179)
[33m[7040 ms][robot_manager] - WARNING : 
[33mRobot mass: 1.2400000467896461,
[33mInertia: tensor([[0.0134, 0.0000, 0.0000],
[33m        [0.0000, 0.0144, 0.0000],
[33m        [0.0000, 0.0000, 0.0138]], device='cuda:0'),
[33mRobot COM: tensor([[0., 0., 0., 1.]], device='cuda:0') (robot_manager.py:427)
[33m[7041 ms][robot_manager] - WARNING : Calculated robot mass and inertia for this robot. This code assumes that your robot is the same across environments. (robot_manager.py:430)
[31m[7041 ms][robot_manager] - CRITICAL : If your robot differs across environments you need to perform this computation for each different robot here. (robot_manager.py:433)
[37m[7206 ms][env_manager] - INFO : [DONE] Populating environments. (env_manager.py:75)
[33m[7222 ms][IsaacGymEnvManager] - WARNING : Headless: True (IGE_env_manager.py:424)
[37m[7222 ms][IsaacGymEnvManager] - INFO : Headless mode. Viewer not created. (IGE_env_manager.py:434)
[33m[7409 ms][asset_manager] - WARNING : Number of obstacles to be kept in the environment: 9 (asset_manager.py:32)
/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.min_thrust, device=self.device, dtype=torch.float32).expand(
/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/control/motor_model.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.max_thrust, device=self.device, dtype=torch.float32).expand(
[33m[7659 ms][control_allocation] - WARNING : Control allocation does not account for actuator limits. This leads to suboptimal allocation (control_allocation.py:48)
[37m[7660 ms][WarpSensor] - INFO : Camera sensor initialized (warp_sensor.py:50)
/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/vae_image_encoder.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = clean_state_dict(torch.load(weight_file_path))
/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/gym/spaces/box.py:84: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py:254: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(enabled=self.mixed_precision)
[31m[9471 ms][navigation_task] - CRITICAL : Crash is happening too soon. (navigation_task.py:195)
[31m[9472 ms][navigation_task] - CRITICAL : Envs crashing too soon: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
[31m         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
[31m         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
[31m         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
[31m         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
[31m         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
[31m         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
[31m         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
[31m        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
[31m        126, 127], device='cuda:0') (navigation_task.py:196)
[31m[9473 ms][navigation_task] - CRITICAL : Time at crash: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
[31m        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.int32) (navigation_task.py:197)
creating render graph
Module warp.utils load on device 'cuda:0' took 1.28 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_camera_kernels load on device 'cuda:0' took 6.56 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_stereo_camera_kernels load on device 'cuda:0' took 18.04 ms
Module aerial_gym.sensors.warp.warp_kernels.warp_lidar_kernels load on device 'cuda:0' took 4.91 ms
finishing capture of render graph
Encoder network initialized.
Defined encoder.
[ImgDecoder] Starting create_model
[ImgDecoder] Done with create_model
Defined decoder.
Loading weights from file:  /home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/utils/vae/weights/ICRA_test_set_more_sim_data_kld_beta_3_LD_64_epoch_49.pth
Box(-1.0, 1.0, (4,), float32) Box(-inf, inf, (81,), float32)
seq_length: 4
current training device: cuda:0
build mlp: 81
RunningMeanStd:  (1,)
RunningMeanStd:  (81,)
/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/algos_torch/a2c_continuous.py:106: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.mixed_precision):
fps step: 712 fps step and policy inference: 706 fps total: 695 epoch: 1/500 frames: 0
fps step: 1623 fps step and policy inference: 1605 fps total: 1588 epoch: 2/500 frames: 4096
fps step: 1604 fps step and policy inference: 1586 fps total: 1575 epoch: 3/500 frames: 8192
fps step: 1579 fps step and policy inference: 1562 fps total: 1552 epoch: 4/500 frames: 12288
fps step: 1585 fps step and policy inference: 1568 fps total: 1558 epoch: 5/500 frames: 16384
fps step: 1602 fps step and policy inference: 1584 fps total: 1573 epoch: 6/500 frames: 20480
Traceback (most recent call last):
  File "runner.py", line 328, in <module>
    runner.run(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 133, in run
    self.run_train(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 116, in run_train
    agent.train()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1318, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1182, in train_epoch
    batch_dict = self.play_steps()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 752, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 519, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "runner.py", line 57, in step
    return self.env.step(actions)
  File "runner.py", line 35, in step
    observations, rewards, terminated, truncated, infos = super().step(action)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 346, in step
    self.post_image_reward_addition()
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 355, in post_image_reward_addition
    self.rewards[self.terminations < 0] += -exponential_reward_function(
KeyboardInterrupt
Traceback (most recent call last):
  File "runner.py", line 328, in <module>
    runner.run(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 133, in run
    self.run_train(args)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/torch_runner.py", line 116, in run_train
    agent.train()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1318, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses, entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 1182, in train_epoch
    batch_dict = self.play_steps()
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 752, in play_steps
    self.obs, rewards, self.dones, infos = self.env_step(res_dict['actions'])
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/rl_games/common/a2c_common.py", line 519, in env_step
    obs, rewards, dones, infos = self.vec_env.step(actions)
  File "runner.py", line 57, in step
    return self.env.step(actions)
  File "runner.py", line 35, in step
    observations, rewards, terminated, truncated, infos = super().step(action)
  File "/home/shruti/miniconda3/envs/safe-rl/lib/python3.8/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 346, in step
    self.post_image_reward_addition()
  File "/home/shruti/workspaces/aerial_gym_ws/src/aerial_gym_simulator/aerial_gym/task/navigation_task/navigation_task.py", line 355, in post_image_reward_addition
    self.rewards[self.terminations < 0] += -exponential_reward_function(
KeyboardInterrupt
fps step: 1602 fps step and policy inference: 1583 fps total: 1573 epoch: 7/500 frames: 24576