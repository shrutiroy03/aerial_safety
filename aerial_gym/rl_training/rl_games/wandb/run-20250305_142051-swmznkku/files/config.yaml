wandb_version: 1

params:
  desc: null
  value:
    seed: 8
    algo:
      name: a2c_continuous
    model:
      name: continuous_a2c_logstd
    load_checkpoint: false
    network:
      name: actor_critic
      separate: false
      space:
        continuous:
          mu_activation: None
          sigma_activation: None
          mu_init:
            name: default
          sigma_init:
            name: const_initializer
            val: 0
          fixed_sigma: true
      mlp:
        units:
        - 256
        - 128
        - 64
        d2rl: false
        activation: elu
        initializer:
          name: default
          scale: 2
    config:
      env_name: dce_navigation_task
      env_config:
        num_envs: 512
        headless: true
        use_warp: true
      name: gen_ppo
      reward_shaper:
        scale_value: 0.1
      normalize_advantage: true
      gamma: 0.99
      tau: 0.95
      ppo: true
      learning_rate: 1e-4
      lr_schedule: adaptive
      kl_threshold: 0.016
      save_best_after: 10
      score_to_win: 100000
      grad_norm: 1.0
      entropy_coef: 0.0001
      truncate_grads: true
      e_clip: 0.2
      clip_value: false
      num_actors: 512
      horizon_length: 32
      minibatch_size: 8192
      mini_epochs: 4
      critic_coef: 2
      normalize_input: false
      bounds_loss_coef: 0.0001
      max_epochs: 400
      normalize_value: true
      use_diagnostics: true
      value_bootstrap: true
      use_smooth_clamp: false
      player:
        use_vecenv: true
_wandb:
  desc: null
  value:
    code_path: code/aerial_gym/rl_training/rl_games/runner.py
    python_version: 3.8.20
    cli_version: 0.16.6
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1741202451.0
    t:
      1:
      - 1
      - 55
      3:
      - 16
      - 23
      - 35
      4: 3.8.20
      5: 0.16.6
      8:
      - 5
      13: linux-x86_64
